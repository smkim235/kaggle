{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reference*\n",
    "- Raschka, S. (2015). Python Machine Learning. Packt Publishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDb_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...          1\n",
       "1  Homelessness (or Houselessness as George Carli...          1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...          1\n",
       "3  This is easily the most underrated film inn th...          1\n",
       "4  This is not the typical Mel Brooks film. It wa...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'sam']\n",
      "['job', 'titl', 'softwar', 'engin']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def test(s):\n",
    "    # remove html tag\n",
    "    pattern = r'\\<[^>]*\\>'\n",
    "    s = re.sub(pattern, '', s.lower())\n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    words = [porter.stem(word) for word in s.split(' ') if word not in stop and word != '']\n",
    "    \n",
    "    return words\n",
    "    \n",
    "s = 'My name is <br/> Sam<br>'\n",
    "s2 = 'Your job title is Software Engineer'\n",
    "print(test(s))\n",
    "print(test(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1]]\n",
      "{'they': 6, 'and': 0, 'run': 3, 'runners': 4, 'br': 1, 'thus': 7, 'running': 5, 'like': 2}\n",
      "[[ 0.35355339  0.35355339  0.35355339  0.35355339  0.35355339  0.35355339\n",
      "   0.35355339  0.35355339]]\n",
      "{'they': 6, 'and': 0, 'run': 3, 'runners': 4, 'br': 1, 'thus': 7, 'running': 5, 'like': 2}\n",
      "[[ 0.37796447  0.75592895  0.37796447  0.37796447]]\n",
      "{'thu': 3, 'runner': 2, 'run': 1, 'like': 0}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocessor(s): \n",
    "    # remove html tag\n",
    "    pattern = r'\\<[^>]*\\>'\n",
    "    s = re.sub(pattern, '', s.lower())\n",
    "    return s\n",
    "    \n",
    "def tokenizer_porter(s):\n",
    "    porter = PorterStemmer()\n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    words = [porter.stem(word) for word in s.split(' ') if word not in stop and word != '']\n",
    "    return words\n",
    "\n",
    "s = 'runners like running<br> and thus they run'\n",
    "\n",
    "countv = CountVectorizer()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf2 = TfidfVectorizer(preprocessor=preprocessor,\n",
    "        tokenizer=tokenizer_porter)\n",
    "\n",
    "print(countv.fit_transform([s]).toarray())\n",
    "print(countv.vocabulary_)\n",
    "print(tfidf.fit_transform([s]).toarray())\n",
    "print(tfidf.vocabulary_)\n",
    "print(tfidf2.fit_transform([s]).toarray())\n",
    "print(tfidf2.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. tf-idf and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory overflow: use only 5000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df.sample(5000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50.08\n",
       "1    49.92\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = df2.sentiment.value_counts()\n",
    "cnt_p = cnt/cnt.sum()*100\n",
    "cnt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = df2.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(preprocessor=preprocessor,\n",
    "        tokenizer=tokenizer_porter)\n",
    "\n",
    "X = tfidf.fit_transform(docs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df2.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 83128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(penalty='l2', C=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 96.77 %\n",
      "test accuracy: 83.40 %\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: %.2f %%' %(clf.score(X_train, y_train)*100))\n",
    "print('test accuracy: %.2f %%' %(clf.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOQAAADpCAYAAAA0yZtTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26a575f3f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.81      0.83       754\n",
      "          1       0.82      0.86      0.84       746\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(2.5,2.5))\n",
    "ax.matshow(mat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(x=j,y=i,s=mat[i,j], ha='center', va='center')\n",
    "plt.show()\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Online algorithm using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_doc(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text,label\n",
    "            \n",
    "def get_minibatch(gen_doc, size):\n",
    "    text_list = []\n",
    "    label_list = []\n",
    "    cnt = 0\n",
    "    for text, label in gen_doc:\n",
    "        text_list.append(text)\n",
    "        label_list.append(label)\n",
    "        \n",
    "        cnt += 1\n",
    "        if cnt >= size:\n",
    "            break\n",
    "        \n",
    "    return text_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21, \n",
    "                         preprocessor=preprocessor, \n",
    "                         tokenizer=tokenizer_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='log', random_state=0, n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_doc = generate_doc('IMDb_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                100%\n",
      "[####################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:47\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "n = 20\n",
    "pbar = pyprind.ProgBar(n)\n",
    "train_acc = []\n",
    "for _ in range(n):\n",
    "    X_train, y_train = get_minibatch(gen_doc, size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "        \n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=np.array([0,1]))\n",
    "    \n",
    "    train_acc.append(clf.score(X_train, y_train)*100)\n",
    "    \n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 87.400000000000006,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test, y_test = get_minibatch(gen_doc, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('test accuracy: %.5f' %(accuracy_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
