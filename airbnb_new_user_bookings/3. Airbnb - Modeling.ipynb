{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Semin Kim. Last Update: 2017/01/07."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(joint with Isaac Solomon from Brown University)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the combined user data for analysis. \n",
    "Since the input dimension is quite large (~350), we first apply a random forest and logistic regression.\n",
    "\n",
    "We test models for\n",
    "- use user_info.\n",
    "- use actions vector. \n",
    "    - try action types, action details, and actions\n",
    "    - also try tf-idf transformation  \n",
    "- use actions_sec vector similarly to actions vector.\n",
    "- the combination of above. \n",
    "\n",
    "We only present the best model, which is\n",
    "- use user_info and actions without seconds and without tf-idf. \n",
    "- apply a random forest with 20 estimators and 10 tree depth, and 100 max features. \n",
    "- or apply a logistic regression. \n",
    "\n",
    "We achieve around 79% of accuracy from 5-fold CV from either model,\n",
    "which is a 10% increase in accuracy compared to the base accuracy 69%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_user_session_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65136, 679)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_info = ['gender', 'ageCat','signup_method', 'signup_flow',\n",
    "       'language', 'affiliate_channel', 'affiliate_provider',\n",
    "       'signup_app', 'first_device_type', 'first_browser']\n",
    "\n",
    "target = 'country_destination'\n",
    "\n",
    "actions = pd.read_csv('actions.csv', header=None, names=['action']).action.tolist()\n",
    "actions_sec = [action+'_sec' for action in actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "feature_columns += user_info\n",
    "feature_columns += actions\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65136, 339)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ageCat</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "      <th>...</th>\n",
       "      <th>similar_listings_v2</th>\n",
       "      <th>confirmation</th>\n",
       "      <th>signup_weibo</th>\n",
       "      <th>acculynk_load_pin_pad</th>\n",
       "      <th>acculynk_bin_check_success</th>\n",
       "      <th>acculynk_session_obtained</th>\n",
       "      <th>acculynk_pin_pad_inactive</th>\n",
       "      <th>reactivate</th>\n",
       "      <th>airbrb</th>\n",
       "      <th>desks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  ageCat  signup_method  signup_flow  language  affiliate_channel  \\\n",
       "0       0       2              0            0         0                  2   \n",
       "1       0       2              0            0         0                  5   \n",
       "2       0       2              0            0         0                  2   \n",
       "3       0       2              0            0         0                  2   \n",
       "4       1       4              1            0         0                  7   \n",
       "\n",
       "   affiliate_provider  signup_app  first_device_type  first_browser  ...    \\\n",
       "0                   0           2                  1              5  ...     \n",
       "1                   1           2                  2              5  ...     \n",
       "2                   0           2                  2              2  ...     \n",
       "3                   0           2                  3              7  ...     \n",
       "4                   1           2                  3              7  ...     \n",
       "\n",
       "   similar_listings_v2  confirmation  signup_weibo  acculynk_load_pin_pad  \\\n",
       "0                    0             0             0                      0   \n",
       "1                    0             0             0                      0   \n",
       "2                    0             0             0                      0   \n",
       "3                    0             0             0                      0   \n",
       "4                    0             0             0                      0   \n",
       "\n",
       "   acculynk_bin_check_success  acculynk_session_obtained  \\\n",
       "0                           0                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "\n",
       "   acculynk_pin_pad_inactive  reactivate  airbrb  desks  \n",
       "0                          0           0       0      0  \n",
       "1                          0           0       0      0  \n",
       "2                          0           0       0      0  \n",
       "3                          0           0       0      0  \n",
       "4                          0           0       0      0  \n",
       "\n",
       "[5 rows x 339 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69.149165\n",
       "1    30.850835\n",
       "Name: country_destination, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cnt = y.value_counts()\n",
    "y_cnt_percent = y_cnt/y_cnt.sum()*100\n",
    "y_cnt_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "def printFeatureImportance(clf, X,y):\n",
    "    print('\\n feature importance:')\n",
    "    clf.fit(X, y)\n",
    "    features = X.columns\n",
    "    importances = clf.feature_importances_\n",
    "    arg_sort = np.argsort(importances)[::-1]\n",
    "    n = min(len(features), 10)\n",
    "    for i in range(n):\n",
    "        idx = arg_sort[i]\n",
    "        print('%2d. %-*s %.2f %%' %(i+1,15, features[idx],importances[idx]*100))\n",
    "\n",
    "def fitTree(X,y, estimator=RandomForestClassifier, param_grid=None, cv=2):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
    "    \n",
    "    clf = estimator()\n",
    "     \n",
    "    if param_grid:\n",
    "        gs = GridSearchCV(estimator=clf,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        clf = gs.best_estimator_\n",
    "        print('best param: ' + str(gs.best_params_))\n",
    "        print('grid search time: %.2f sec.' %(time.time()-t1))\n",
    "    \n",
    "    train_scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv)\n",
    "    test_scores = cross_val_score(estimator=clf, X=X_test, y=y_test, cv=cv)\n",
    "    \n",
    "    print('train mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(train_scores)*100, np.std(train_scores)*100))\n",
    "    print('test mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(test_scores)*100, np.std(test_scores)*100))\n",
    "    \n",
    "    printFeatureImportance(clf,X,y)\n",
    "    print('\\n total time: %.2f sec.' %(time.time()-t1))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 76.70 % (std=0.05 %)\n",
      "test mean accuracy: 76.16 % (std=0.21 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          9.12 %\n",
      " 2. gender          4.72 %\n",
      " 3. missing         3.96 %\n",
      " 4. show            3.87 %\n",
      " 5. pending         3.34 %\n",
      " 6. index           3.03 %\n",
      " 7. first_browser   2.84 %\n",
      " 8. personalize     2.58 %\n",
      " 9. requested       2.34 %\n",
      "10. verify          2.29 %\n",
      "\n",
      " total time: 5.72 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest without parameter tuning\n",
    "fitTree(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'max_features': 100, 'max_depth': 10, 'n_estimators': 20}\n",
      "grid search time: 25.45 sec.\n",
      "train mean accuracy: 79.95 % (std=0.33 %)\n",
      "test mean accuracy: 78.97 % (std=0.53 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          24.91 %\n",
      " 2. requested       15.16 %\n",
      " 3. pending         10.91 %\n",
      " 4. gender          6.90 %\n",
      " 5. missing         6.53 %\n",
      " 6. signup_method   5.66 %\n",
      " 7. at_checkpoint   1.97 %\n",
      " 8. verify          1.63 %\n",
      " 9. complete_status 1.63 %\n",
      "10. create          1.59 %\n",
      "\n",
      " total time: 60.38 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest with parameter tuning\n",
    "param_grid = [{'n_estimators':[20], 'max_features':[100], 'max_depth':[10]}]\n",
    "fitTree(X,y, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 79.51 % (std=0.33 %)\n",
      "test mean accuracy: 79.14 % (std=0.33 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          16.29 %\n",
      " 2. pending         7.88 %\n",
      " 3. missing         5.36 %\n",
      " 4. signup_method   4.71 %\n",
      " 5. affiliate_channel 3.53 %\n",
      " 6. manage_listing  3.26 %\n",
      " 7. gender          2.77 %\n",
      " 8. at_checkpoint   2.73 %\n",
      " 9. cancellation_policies 2.60 %\n",
      "10. other_hosting_reviews_first 2.58 %\n",
      "\n",
      " total time: 266.51 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting tree without parameter tuning\n",
    "fitTree(X,y, estimator=GradientBoostingClassifier, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def fitLR(X,y, estimator=LogisticRegression, param_grid=None, cv=2):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    ohe = OneHotEncoder(categorical_features=[0,1,2,3,4,5,6,7,8,9])\n",
    "    X_ohe = ohe.fit_transform(X).toarray()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_ohe,y, test_size=0.3)\n",
    "    \n",
    "    clf = Pipeline([ ('scl', StandardScaler()),\n",
    "                    ('clf', estimator()) ])\n",
    "    \n",
    "    if param_grid:\n",
    "        pipe_param_grid = []\n",
    "        for param in param_grid:\n",
    "            pipe_param = {}\n",
    "            for key,value in param.items():\n",
    "                pipe_param['clf__'+key] = value\n",
    "            pipe_param_grid.append(pipe_param)\n",
    "            \n",
    "        gs = GridSearchCV(estimator=clf,\n",
    "                    param_grid=pipe_param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        clf = gs.best_estimator_\n",
    "        print('best param: ' + str(gs.best_params_))\n",
    "        print('grid search time: %.2f sec.' %(time.time()-t1))\n",
    "    \n",
    "    train_scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv)\n",
    "    test_scores = cross_val_score(estimator=clf, X=X_test, y=y_test, cv=cv)\n",
    "    \n",
    "    print('train mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(train_scores)*100, np.std(train_scores)*100))\n",
    "    print('test mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(test_scores)*100, np.std(test_scores)*100))\n",
    "    \n",
    "    print('\\n total time: %.2f sec.' %(time.time()-t1))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 78.84 % (std=0.26 %)\n",
      "test mean accuracy: 78.51 % (std=0.30 %)\n",
      "\n",
      " total time: 145.73 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression without parameter tuning\n",
    "fitLR(X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that the logistic regression performly similarly to tree-based classifiers because our feature vectors have a very high dimension of 350, and easier to separate linearly.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
