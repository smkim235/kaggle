{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Semin Kim. Last Update: 2017/01/07."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(joint with Isaac Solomon from Brown University)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the combined user data for analysis. \n",
    "Since the input dimension is quite large (~350), we first apply a random forest and logistic regression.\n",
    "\n",
    "We test models for\n",
    "- use user_info.\n",
    "- use actions vector. \n",
    "    - try action types, action details, and actions\n",
    "    - also try tf-idf transformation  \n",
    "- use actions_sec vector similarly to actions vector.\n",
    "- the combination of above. \n",
    "\n",
    "We only present the best model, which is\n",
    "- use user_info and actions without seconds and without tf-idf. \n",
    "- apply a random forest with 20 estimators and 10 tree depth, and 100 max features. \n",
    "- apply a logistic regression. \n",
    "\n",
    "We achieve around 79% of accuracy from 5-fold CV from either model,\n",
    "which is a 10% increase in accuracy compared to the base accuracy 69%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_user_session_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65136, 679)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_info = ['gender', 'ageCat','signup_method', 'signup_flow',\n",
    "       'language', 'affiliate_channel', 'affiliate_provider',\n",
    "       'signup_app', 'first_device_type', 'first_browser']\n",
    "\n",
    "target = 'country_destination'\n",
    "\n",
    "actions = pd.read_csv('actions.csv', header=None, names=['action']).action.tolist()\n",
    "actions_sec = [action+'_sec' for action in actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "feature_columns += user_info\n",
    "feature_columns += actions\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65136, 339)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ageCat</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "      <th>...</th>\n",
       "      <th>similar_listings_v2</th>\n",
       "      <th>confirmation</th>\n",
       "      <th>signup_weibo</th>\n",
       "      <th>acculynk_load_pin_pad</th>\n",
       "      <th>acculynk_bin_check_success</th>\n",
       "      <th>acculynk_session_obtained</th>\n",
       "      <th>acculynk_pin_pad_inactive</th>\n",
       "      <th>reactivate</th>\n",
       "      <th>airbrb</th>\n",
       "      <th>desks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  ageCat  signup_method  signup_flow  language  affiliate_channel  \\\n",
       "0       0       1              0            0         5                  2   \n",
       "1       0       1              0            0         5                  5   \n",
       "2       0       1              0            0         5                  2   \n",
       "3       0       1              0            0         5                  2   \n",
       "4       1       3              1            0         5                  7   \n",
       "\n",
       "   affiliate_provider  signup_app  first_device_type  first_browser  ...    \\\n",
       "0                   3           2                  3             10  ...     \n",
       "1                   7           2                  6             10  ...     \n",
       "2                   3           2                  6              6  ...     \n",
       "3                   3           2                  7             18  ...     \n",
       "4                   7           2                  7             18  ...     \n",
       "\n",
       "   similar_listings_v2  confirmation  signup_weibo  acculynk_load_pin_pad  \\\n",
       "0                    0             0             0                      0   \n",
       "1                    0             0             0                      0   \n",
       "2                    0             0             0                      0   \n",
       "3                    0             0             0                      0   \n",
       "4                    0             0             0                      0   \n",
       "\n",
       "   acculynk_bin_check_success  acculynk_session_obtained  \\\n",
       "0                           0                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "\n",
       "   acculynk_pin_pad_inactive  reactivate  airbrb  desks  \n",
       "0                          0           0       0      0  \n",
       "1                          0           0       0      0  \n",
       "2                          0           0       0      0  \n",
       "3                          0           0       0      0  \n",
       "4                          0           0       0      0  \n",
       "\n",
       "[5 rows x 339 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69.149165\n",
       "1    30.850835\n",
       "Name: country_destination, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cnt = y.value_counts()\n",
    "y_cnt_percent = y_cnt/y_cnt.sum()*100\n",
    "y_cnt_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "def printFeatureImportance(clf, X,y):\n",
    "    print('\\n feature importance:')\n",
    "    clf.fit(X, y)\n",
    "    features = X.columns\n",
    "    importances = clf.feature_importances_\n",
    "    arg_sort = np.argsort(importances)[::-1]\n",
    "    n = min(len(features), 10)\n",
    "    for i in range(n):\n",
    "        idx = arg_sort[i]\n",
    "        print('%2d. %-*s %.2f %%' %(i+1,15, features[idx],importances[idx]*100))\n",
    "\n",
    "def fitTree(X,y, estimator=RandomForestClassifier, param_grid=None, cv=2):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
    "    \n",
    "    clf = estimator()\n",
    "     \n",
    "    if param_grid:\n",
    "        gs = GridSearchCV(estimator=clf,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        clf = gs.best_estimator_\n",
    "        print('best param: ' + str(gs.best_params_))\n",
    "        print('grid search time: %.2f sec.' %(time.time()-t1))\n",
    "    \n",
    "    train_scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv)\n",
    "    test_scores = cross_val_score(estimator=clf, X=X_test, y=y_test, cv=cv)\n",
    "    \n",
    "    print('train mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(train_scores)*100, np.std(train_scores)*100))\n",
    "    print('test mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(test_scores)*100, np.std(test_scores)*100))\n",
    "    \n",
    "    printFeatureImportance(clf,X,y)\n",
    "    print('\\n total time: %.2f sec.' %(time.time()-t1))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 76.30 % (std=0.21 %)\n",
      "test mean accuracy: 76.57 % (std=0.12 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          8.37 %\n",
      " 2. gender          4.61 %\n",
      " 3. show            3.89 %\n",
      " 4. requested       3.25 %\n",
      " 5. index           3.04 %\n",
      " 6. first_browser   2.90 %\n",
      " 7. missing         2.79 %\n",
      " 8. personalize     2.62 %\n",
      " 9. pending         2.47 %\n",
      "10. ajax_refresh_subtotal 2.34 %\n",
      "\n",
      " total time: 5.84 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest without parameter tuning\n",
    "fitTree(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'max_depth': 10, 'max_features': 100, 'n_estimators': 20}\n",
      "grid search time: 24.91 sec.\n",
      "train mean accuracy: 79.63 % (std=0.35 %)\n",
      "test mean accuracy: 79.08 % (std=0.18 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          25.31 %\n",
      " 2. requested       14.39 %\n",
      " 3. pending         9.61 %\n",
      " 4. missing         7.27 %\n",
      " 5. gender          6.38 %\n",
      " 6. signup_method   5.67 %\n",
      " 7. verify          4.18 %\n",
      " 8. at_checkpoint   1.72 %\n",
      " 9. manage_listing  1.45 %\n",
      "10. complete_status 1.37 %\n",
      "\n",
      " total time: 62.14 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest with parameter tuning\n",
    "param_grid = [{'n_estimators':[20], 'max_features':[100], 'max_depth':[10]}]\n",
    "fitTree(X,y, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 79.54 % (std=0.33 %)\n",
      "test mean accuracy: 78.97 % (std=0.70 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          12.36 %\n",
      " 2. pending         7.55 %\n",
      " 3. signup_method   5.28 %\n",
      " 4. missing         4.34 %\n",
      " 5. manage_listing  3.34 %\n",
      " 6. affiliate_channel 3.25 %\n",
      " 7. at_checkpoint   2.74 %\n",
      " 8. cancellation_policies 2.69 %\n",
      " 9. other_hosting_reviews_first 2.65 %\n",
      "10. gender          2.56 %\n",
      "\n",
      " total time: 262.70 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting tree without parameter tuning\n",
    "fitTree(X,y, estimator=GradientBoostingClassifier, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def fitLR(X,y, estimator=LogisticRegression, param_grid=None, cv=2):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    ohe = OneHotEncoder(categorical_features=[0,1,2,3,4,5,6,7,8,9])\n",
    "    X_ohe = ohe.fit_transform(X).toarray()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_ohe,y, test_size=0.3)\n",
    "    \n",
    "    clf = Pipeline([ ('scl', StandardScaler()),\n",
    "                    ('clf', estimator()) ])\n",
    "    \n",
    "    if param_grid:\n",
    "        pipe_param_grid = []\n",
    "        for param in param_grid:\n",
    "            pipe_param = {}\n",
    "            for key,value in param.items():\n",
    "                pipe_param['clf__'+key] = value\n",
    "            pipe_param_grid.append(pipe_param)\n",
    "            \n",
    "        gs = GridSearchCV(estimator=clf,\n",
    "                    param_grid=pipe_param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        clf = gs.best_estimator_\n",
    "        print('best param: ' + str(gs.best_params_))\n",
    "        print('grid search time: %.2f sec.' %(time.time()-t1))\n",
    "    \n",
    "    train_scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv)\n",
    "    test_scores = cross_val_score(estimator=clf, X=X_test, y=y_test, cv=cv)\n",
    "    \n",
    "    print('train mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(train_scores)*100, np.std(train_scores)*100))\n",
    "    print('test mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(test_scores)*100, np.std(test_scores)*100))\n",
    "    \n",
    "    print('\\n total time: %.2f sec.' %(time.time()-t1))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 78.65 % (std=0.19 %)\n",
      "test mean accuracy: 78.75 % (std=0.47 %)\n",
      "\n",
      " total time: 175.60 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression without parameter tuning\n",
    "fitLR(X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that the logistic regression performly similarly to tree-based classifiers because our feature vectors have a very high dimension of 350, and easier to separate linearly.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
