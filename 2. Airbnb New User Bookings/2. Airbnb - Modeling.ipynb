{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Plan\n",
    "\n",
    "### Features\n",
    "- use user_info.\n",
    "- use actions vector. \n",
    "- try action types, action details, and actions\n",
    "- also, try tf-idf transformation  \n",
    "- use actions_sec vector similarly to actions vector.\n",
    "- the combination of above. \n",
    "\n",
    "### The best feature combination\n",
    "(based on 5-fold CV accuracy)\n",
    "- user_info\n",
    "- actions\n",
    "- without seconds\n",
    "- without tf-idf \n",
    "\n",
    "### Model\n",
    "- We first use only user information and apply a decision tree to understand the relation between user information and booking. \n",
    "- Next, we use user information and user activity vectors and apply a logistic regression. We have a logistic regression because features have a high dimension of ~350, and it would be (relatively) easier to separate linearly. \n",
    "- We apply a random forest for the feature analysis and comparision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "### A decision tree with user information\n",
    "- We see no improvement over a simple guess.\n",
    "\n",
    "### A logistic regression with activity vectors.\n",
    "- With user activity vectors, we get around 8% increase in accuracy. \n",
    "\n",
    "### A random forest: feature analysis\n",
    "- We get around 9% increase in accuracy with a random forest. \n",
    "- We see that ageCat has the highest importance as we saw in the exploratory analysis. (missing age -> no booking)\n",
    "- signup_method plays an important role while we didn't see it in the exploratory analysis. We need further analysis for this. \n",
    "- We see that activities like 'pending', 'requested' are an important feature for booking analysis. It could be a good starting point to analyze session data. \n",
    "\n",
    "### Using all data\n",
    "- Overall, we achieve around 79% of accuracy, which is a 10% increase in accuracy compared to the base accuracy 69%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_origin = pd.read_csv('train_user_session_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65136, 676)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_info = ['gender', 'ageCat','signup_method', 'signup_flow',\n",
    "           'language', 'affiliate_channel', 'affiliate_provider',\n",
    "           'signup_app', 'first_device_type', 'first_browser','signup_device']\n",
    "\n",
    "for col in user_info:\n",
    "    df_origin[col] = LabelEncoder().fit_transform(df_origin[col])\n",
    "\n",
    "target = 'country_destination'\n",
    "\n",
    "actions = pd.read_csv('actions.csv', header=None, names=['action']).action.tolist()\n",
    "actions_sec = [action+'_sec' for action in actions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_sample = 20000\n",
    "df = df_origin.sample(n_sample, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDF    69.149165\n",
       "US     30.850835\n",
       "Name: country_destination, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original data\n",
    "y_cnt = df_origin.country_destination.value_counts()\n",
    "y_cnt_percent = y_cnt/y_cnt.sum()*100\n",
    "y_cnt_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDF    69.2\n",
       "US     30.8\n",
       "Name: country_destination, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampled data\n",
    "y_cnt = df.country_destination.value_counts()\n",
    "y_cnt_percent = y_cnt/y_cnt.sum()*100\n",
    "y_cnt_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that the sample data reflect well on overall booking rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling with user information using a decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "def printFeatureImportance(clf, X,y):\n",
    "    print('\\n feature importance:')\n",
    "    clf.fit(X, y)\n",
    "    features = X.columns\n",
    "    importances = clf.feature_importances_\n",
    "    arg_sort = np.argsort(importances)[::-1]\n",
    "    n = min(len(features), 10)\n",
    "    for i in range(n):\n",
    "        idx = arg_sort[i]\n",
    "        print('%2d. %-*s %.2f %%' %(i+1,15, features[idx],importances[idx]*100))\n",
    "\n",
    "def fitTree(X,y, estimator=DecisionTreeClassifier, param_grid=None, cv=5):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
    "    \n",
    "    clf = estimator()\n",
    "     \n",
    "    if param_grid:\n",
    "        gs = GridSearchCV(estimator=clf,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        clf = gs.best_estimator_\n",
    "        print('best param: ' + str(gs.best_params_))\n",
    "        print('grid search time: %.2f sec.' %(time.time()-t1))\n",
    "    \n",
    "    train_scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv)\n",
    "    test_scores = cross_val_score(estimator=clf, X=X_test, y=y_test, cv=cv)\n",
    "    \n",
    "    print('train mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(train_scores)*100, np.std(train_scores)*100))\n",
    "    print('test mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(test_scores)*100, np.std(test_scores)*100))\n",
    "    \n",
    "    printFeatureImportance(clf,X,y)\n",
    "    print('\\n total time: %.2f sec.' %(time.time()-t1))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "feature_columns += user_info\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 71.91 % (std=0.66 %)\n",
      "test mean accuracy: 70.65 % (std=1.31 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          44.04 %\n",
      " 2. signup_method   14.45 %\n",
      " 3. gender          7.52 %\n",
      " 4. affiliate_channel 7.50 %\n",
      " 5. first_browser   7.04 %\n",
      " 6. first_device_type 4.27 %\n",
      " 7. affiliate_provider 4.09 %\n",
      " 8. language        3.85 %\n",
      " 9. signup_device   2.94 %\n",
      "10. signup_flow     2.35 %\n",
      "\n",
      " total time: 0.46 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitTree(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see no improvement over a simple guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling with user activity vectors using a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "def fitLR(X,y, estimator=LogisticRegression, categorical_features=[], param_grid=None, cv=5, normalize=False, tfidf=False):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    X = X.copy()\n",
    "    numeric_features = [col for idx, col in enumerate(X.columns) if idx not in categorical_features]\n",
    "    if normalize and numeric_features:\n",
    "        stds = StandardScaler()\n",
    "        X[numeric_features] = stds.fit_transform(X[numeric_features])\n",
    "    \n",
    "    if tfidf and numeric_features:\n",
    "        tfidf = TfidfTransformer()\n",
    "        X[numeric_features] = tfidf.fit_transform(X[numeric_features]).toarray()\n",
    "    \n",
    "    X_ohe = X\n",
    "    if categorical_features:\n",
    "        ohe = OneHotEncoder(categorical_features=categorical_features)\n",
    "        X_ohe = ohe.fit_transform(X).toarray()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_ohe,y, test_size=0.3)\n",
    "    \n",
    "    clf = estimator()\n",
    "    \n",
    "    if param_grid:\n",
    "        gs = GridSearchCV(estimator=clf,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        clf = gs.best_estimator_\n",
    "        print('best param: ' + str(gs.best_params_))\n",
    "        print('grid search time: %.2f sec.' %(time.time()-t1))\n",
    "    \n",
    "    train_scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv)\n",
    "    test_scores = cross_val_score(estimator=clf, X=X_test, y=y_test, cv=cv)\n",
    "    \n",
    "    print('train mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(train_scores)*100, np.std(train_scores)*100))\n",
    "    print('test mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(test_scores)*100, np.std(test_scores)*100))\n",
    "    \n",
    "    print('\\n total time: %.2f sec.' %(time.time()-t1))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "feature_columns += user_info\n",
    "feature_columns += actions\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 340)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 78.65 % (std=0.47 %)\n",
      "test mean accuracy: 77.48 % (std=0.70 %)\n",
      "\n",
      " total time: 14.62 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitLR(X, y,categorical_features=[0,1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 78.54 % (std=0.21 %)\n",
      "test mean accuracy: 76.60 % (std=1.26 %)\n",
      "\n",
      " total time: 40.68 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitLR(X, y,categorical_features=[0,1,2,3,4,5,6,7,8,9,10], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with tf-idf Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 78.60 % (std=0.42 %)\n",
      "test mean accuracy: 77.65 % (std=0.68 %)\n",
      "\n",
      " total time: 9.56 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitLR(X, y,categorical_features=[0,1,2,3,4,5,6,7,8,9,10], tfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With user activity vectors, we get around 8% increase in accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Advanced Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'n_estimators': 20, 'max_features': 150, 'max_depth': 10}\n",
      "grid search time: 164.69 sec.\n",
      "train mean accuracy: 78.91 % (std=0.65 %)\n",
      "test mean accuracy: 77.98 % (std=0.74 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          25.08 %\n",
      " 2. pending         12.98 %\n",
      " 3. signup_method   7.38 %\n",
      " 4. requested       7.34 %\n",
      " 5. missing         6.04 %\n",
      " 6. gender          3.68 %\n",
      " 7. verify          3.26 %\n",
      " 8. manage_listing  1.79 %\n",
      " 9. create          1.21 %\n",
      "10. show            1.16 %\n",
      "\n",
      " total time: 177.45 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=150, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'n_estimators':[20,50], 'max_features':[50,100,150], 'max_depth':[5,10,15]}]\n",
    "fitTree(X,y, estimator=RandomForestClassifier, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We get around 9% increase in accuracy with a random forest. \n",
    "- We see that ageCat has the highest importance as we saw in the exploratory analysis. (missing age -> no booking)\n",
    "- signup_method plays an important role while we didn't see it in the exploratory analysis. We need further analysis for this. \n",
    "- We see that activities like 'pending', 'requested' are an important feature for booking analysis. It could be a good starting point to analyze session data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fianlly, we test models using all 650K data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "feature_columns += user_info\n",
    "feature_columns += actions\n",
    "\n",
    "X = df_origin[feature_columns]\n",
    "y = df_origin[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 78.85 % (std=0.20 %)\n",
      "test mean accuracy: 78.92 % (std=0.52 %)\n",
      "\n",
      " total time: 79.20 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitLR(X, y,categorical_features=[0,1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'n_estimators': 50, 'max_features': 100, 'max_depth': 10}\n",
      "grid search time: 59.15 sec.\n",
      "train mean accuracy: 80.03 % (std=0.42 %)\n",
      "test mean accuracy: 79.10 % (std=0.48 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          27.14 %\n",
      " 2. pending         14.37 %\n",
      " 3. missing         9.02 %\n",
      " 4. requested       7.83 %\n",
      " 5. signup_method   5.98 %\n",
      " 6. gender          5.12 %\n",
      " 7. verify          2.29 %\n",
      " 8. create          1.73 %\n",
      " 9. at_checkpoint   1.68 %\n",
      "10. travel_plans_current 1.37 %\n",
      "\n",
      " total time: 140.53 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'n_estimators':[50], 'max_features':[100], 'max_depth':[10]}]\n",
    "fitTree(X,y, estimator=RandomForestClassifier, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We now get around 10% increase in accurary from either model. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
