{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Semin Kim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(joint with Isaac Solomon from Brown University)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the combined user data for analysis. \n",
    "Since the input dimension is quite large (~350), we first apply a random forest and logistic regression.\n",
    "\n",
    "### Features\n",
    "- use user_info.\n",
    "- use actions vector. \n",
    "- try action types, action details, and actions\n",
    "- also try tf-idf transformation  \n",
    "- use actions_sec vector similarly to actions vector.\n",
    "- the combination of above. \n",
    "\n",
    "### The best feature combination\n",
    "(based on 5-fold CV accuracy)\n",
    "- user_info\n",
    "- actions\n",
    "- without seconds\n",
    "- without tf-idf \n",
    "\n",
    "### Model\n",
    "- we use a logistic regression because we have high dimensional feature vectors (~350-dim).\n",
    "- It would be (relatively) easier to separate linearly. \n",
    "\n",
    "### Advanced Models\n",
    "- Once applying a logistic regression, we apply a random forest for comparision. \n",
    "\n",
    "Overall, we achieve around 79% of accuracy from 5-fold CV from either model,\n",
    "which is a 10% increase in accuracy compared to the base accuracy 69%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_user_session_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65136, 676)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#user_info = ['gender', 'ageCat','signup_device']\n",
    "user_info = ['gender', 'ageCat','signup_method', 'signup_flow',\n",
    "           'language', 'affiliate_channel', 'affiliate_provider',\n",
    "           'signup_app', 'first_device_type', 'first_browser','signup_device']\n",
    "    \n",
    "    \n",
    "for col in user_info:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "target = 'country_destination'\n",
    "\n",
    "actions = pd.read_csv('actions.csv', header=None, names=['action']).action.tolist()\n",
    "actions_sec = [action+'_sec' for action in actions]\n",
    "\n",
    "feature_columns = []\n",
    "feature_columns += user_info\n",
    "feature_columns += actions\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65136, 340)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ageCat</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "      <th>...</th>\n",
       "      <th>similar_listings_v2</th>\n",
       "      <th>confirmation</th>\n",
       "      <th>signup_weibo</th>\n",
       "      <th>acculynk_load_pin_pad</th>\n",
       "      <th>acculynk_bin_check_success</th>\n",
       "      <th>acculynk_session_obtained</th>\n",
       "      <th>acculynk_pin_pad_inactive</th>\n",
       "      <th>reactivate</th>\n",
       "      <th>airbrb</th>\n",
       "      <th>desks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  ageCat  signup_method  signup_flow  language  affiliate_channel  \\\n",
       "0       0       2              0            0         5                  2   \n",
       "1       0       2              0            0         5                  5   \n",
       "2       0       2              0            0         5                  2   \n",
       "3       0       2              0            0         5                  2   \n",
       "4       1       4              1            0         5                  7   \n",
       "\n",
       "   affiliate_provider  signup_app  first_device_type  first_browser  ...    \\\n",
       "0                   3           2                  3             10  ...     \n",
       "1                   7           2                  6             10  ...     \n",
       "2                   3           2                  6              6  ...     \n",
       "3                   3           2                  7             18  ...     \n",
       "4                   7           2                  7             18  ...     \n",
       "\n",
       "   similar_listings_v2  confirmation  signup_weibo  acculynk_load_pin_pad  \\\n",
       "0                    0             0             0                      0   \n",
       "1                    0             0             0                      0   \n",
       "2                    0             0             0                      0   \n",
       "3                    0             0             0                      0   \n",
       "4                    0             0             0                      0   \n",
       "\n",
       "   acculynk_bin_check_success  acculynk_session_obtained  \\\n",
       "0                           0                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "\n",
       "   acculynk_pin_pad_inactive  reactivate  airbrb  desks  \n",
       "0                          0           0       0      0  \n",
       "1                          0           0       0      0  \n",
       "2                          0           0       0      0  \n",
       "3                          0           0       0      0  \n",
       "4                          0           0       0      0  \n",
       "\n",
       "[5 rows x 340 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDF    69.149165\n",
       "US     30.850835\n",
       "Name: country_destination, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cnt = y.value_counts()\n",
    "y_cnt_percent = y_cnt/y_cnt.sum()*100\n",
    "y_cnt_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling with a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "def fitLR(X,y, estimator=LogisticRegression, categorical_features=[], param_grid=None, cv=2):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    X = X.copy()\n",
    "    features = [col for idx, col in enumerate(X.columns) if idx not in categorical_features]\n",
    "    X[features] = StandardScaler().fit_transform(X[features])\n",
    "    \n",
    "    X_ohe = X\n",
    "    if categorical_features:\n",
    "        ohe = OneHotEncoder(categorical_features=categorical_features)\n",
    "        X_ohe = ohe.fit_transform(X).toarray()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_ohe,y, test_size=0.3)\n",
    "    \n",
    "    clf = estimator()\n",
    "    \n",
    "    if param_grid:\n",
    "        gs = GridSearchCV(estimator=clf,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        clf = gs.best_estimator_\n",
    "        print('best param: ' + str(gs.best_params_))\n",
    "        print('grid search time: %.2f sec.' %(time.time()-t1))\n",
    "    \n",
    "    train_scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv)\n",
    "    test_scores = cross_val_score(estimator=clf, X=X_test, y=y_test, cv=cv)\n",
    "    \n",
    "    print('train mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(train_scores)*100, np.std(train_scores)*100))\n",
    "    print('test mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(test_scores)*100, np.std(test_scores)*100))\n",
    "    \n",
    "    print('\\n total time: %.2f sec.' %(time.time()-t1))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 78.68 % (std=0.18 %)\n",
      "test mean accuracy: 78.44 % (std=0.08 %)\n",
      "\n",
      " total time: 60.54 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitLR(X, y,categorical_features=[0,1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Advanced Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "def printFeatureImportance(clf, X,y):\n",
    "    print('\\n feature importance:')\n",
    "    clf.fit(X, y)\n",
    "    features = X.columns\n",
    "    importances = clf.feature_importances_\n",
    "    arg_sort = np.argsort(importances)[::-1]\n",
    "    n = min(len(features), 10)\n",
    "    for i in range(n):\n",
    "        idx = arg_sort[i]\n",
    "        print('%2d. %-*s %.2f %%' %(i+1,15, features[idx],importances[idx]*100))\n",
    "\n",
    "def fitTree(X,y, estimator=RandomForestClassifier, param_grid=None, cv=2):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
    "    \n",
    "    clf = estimator()\n",
    "     \n",
    "    if param_grid:\n",
    "        gs = GridSearchCV(estimator=clf,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='accuracy',\n",
    "                    cv=cv)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        clf = gs.best_estimator_\n",
    "        print('best param: ' + str(gs.best_params_))\n",
    "        print('grid search time: %.2f sec.' %(time.time()-t1))\n",
    "    \n",
    "    train_scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=cv)\n",
    "    test_scores = cross_val_score(estimator=clf, X=X_test, y=y_test, cv=cv)\n",
    "    \n",
    "    print('train mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(train_scores)*100, np.std(train_scores)*100))\n",
    "    print('test mean accuracy: %.2f %% (std=%.2f %%)' \n",
    "              %(np.mean(test_scores)*100, np.std(test_scores)*100))\n",
    "    \n",
    "    printFeatureImportance(clf,X,y)\n",
    "    print('\\n total time: %.2f sec.' %(time.time()-t1))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean accuracy: 76.73 % (std=0.15 %)\n",
      "test mean accuracy: 76.01 % (std=0.32 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          9.50 %\n",
      " 2. gender          4.07 %\n",
      " 3. show            3.80 %\n",
      " 4. requested       3.53 %\n",
      " 5. pending         3.09 %\n",
      " 6. missing         3.00 %\n",
      " 7. index           2.91 %\n",
      " 8. first_browser   2.57 %\n",
      " 9. personalize     2.54 %\n",
      "10. ajax_refresh_subtotal 2.35 %\n",
      "\n",
      " total time: 6.04 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'n_estimators':[20], 'max_features':[100], 'max_depth':[10]}]\n",
    "fitTree(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best param: {'max_features': 100, 'max_depth': 10, 'n_estimators': 20}\n",
      "grid search time: 25.45 sec.\n",
      "train mean accuracy: 79.95 % (std=0.33 %)\n",
      "test mean accuracy: 78.97 % (std=0.53 %)\n",
      "\n",
      " feature importance:\n",
      " 1. ageCat          24.91 %\n",
      " 2. requested       15.16 %\n",
      " 3. pending         10.91 %\n",
      " 4. gender          6.90 %\n",
      " 5. missing         6.53 %\n",
      " 6. signup_method   5.66 %\n",
      " 7. at_checkpoint   1.97 %\n",
      " 8. verify          1.63 %\n",
      " 9. complete_status 1.63 %\n",
      "10. create          1.59 %\n",
      "\n",
      " total time: 60.38 sec.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features=100, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest with parameter tuning\n",
    "param_grid = [{'n_estimators':[20, 50], 'max_features':[50,100], 'max_depth':[10, 20]}]\n",
    "fitTree(X,y, param_grid=param_grid, cv=5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
